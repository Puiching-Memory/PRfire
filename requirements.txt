# conda create 
# torch==2.4.0
huggingface_hub==0.29.3
# ultralytics==8.3.73
requests==2.32.3

# $env:HF_ENDPOINT = "https://hf-mirror.com"
# Download Mode: huggingface-cli download --resume-download AIDC-AI/Ovis2-4B --local-dir ./model

# server requirements
fastapi==0.115.11
uvicorn[standard]==0.34.0
python-multipart==0.0.20
fastapi-cache2==0.2.2
pickledb==1.3.2
sse-starlette==2.2.1

# language model requirements
langchain==0.3.20
langchain_community==0.3.19
langchain_openai==0.3.8


# optional
# flash-attn==2.7.0.post2 # GET it from https://huggingface.co/lldacing/flash-attention-windows-wheel/tree/main

