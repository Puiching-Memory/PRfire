# python==3.11
# torch==2.5.1(cu124)
huggingface_hub==0.28.1
lmdeploy==0.7.0
ultralytics==8.3.73

# server requirements
fastapi==0.115.8
uvicorn[standard]==0.34.0
python-multipart==0.0.20
fastapi-cache2==0.2.2
pickledb==1.3.2

# language model requirements
langchain==0.3.18
langchain_community==0.3.17
duckduckgo-search==7.3.2

py-cpuinfo==9.0.0
deepspeed==0.15.0 # for windows, download from https://pypi.org/project/deepspeed/0.15.0/#files

-r InternVL/requirements/internvl_chat.txt

# optional
# flash-attn==2.7.0.post2 # GET it from https://huggingface.co/lldacing/flash-attention-windows-wheel/tree/main

